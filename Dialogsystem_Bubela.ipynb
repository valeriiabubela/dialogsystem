{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49253577",
   "metadata": {},
   "source": [
    "# Corona Chatbot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae58c12",
   "metadata": {},
   "source": [
    "### Table of contests\n",
    "1. [Imports](#Imports)\n",
    "2. [Input: speech recording and STT](#Input_speech_recording_and_STT)\n",
    "3. [Semantic parsing](#Semantic_parsing)\n",
    "4. [Data binding](#Data_binding)\n",
    "5. [Output and TTS](#Output_and_TTS)\n",
    "6. [Dialog manager](#Dialog_manager)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7666e9a3",
   "metadata": {},
   "source": [
    "### <a id=\"Imports\">Imports</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "692fe1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import eliza\n",
    "import os\n",
    "import sounddevice as sd\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "from scipy.io.wavfile import write\n",
    "import json\n",
    "from wendel_util import file_update #creates / updates a json file with data from Corona API\n",
    "from google.cloud import speech\n",
    "import io\n",
    "import random\n",
    "import pickle\n",
    "import self\n",
    "import pyttsx3\n",
    "import nltk #used for word tokenization\n",
    "\n",
    "import spacy #used for NER - named entity recognition\n",
    "nlp = spacy.load(\"de_core_news_lg\")\n",
    "\n",
    "from HanTa import HanoverTagger as ht #used for lemmatization; performs better than spaCy for German\n",
    "hannover = ht.HanoverTagger('morphmodel_ger.pgz')\n",
    "\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e485cc3",
   "metadata": {},
   "source": [
    "### <a id=\"Input_speech_recording_and_STT\">Input: speech recording and STT</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a1437cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#record the input question (3s) and save it as a wav file\n",
    "def record_file():\n",
    "    filename = 'myfile.wav'\n",
    "    sr = 16000  #sample rate\n",
    "    seconds = 3  #duration of recording\n",
    "    data = sd.rec(int(seconds * sr), samplerate=sr, channels=1)\n",
    "    sd.wait()  #wait until recording is finished\n",
    "    #convert `data` to 16 bit integers:\n",
    "    y = (np.iinfo(np.int16).max * (data/np.abs(data).max())).astype(np.int16) \n",
    "    write(filename, sr, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c5e9f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "credentials='dazzling-trail-316220-8e991214f1c8.json'\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]=credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e628e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#transcribe the audio file and return the transcription\n",
    "def transcribe():\n",
    "    filename = 'myfile.wav'\n",
    "    client = speech.SpeechClient()\n",
    "    with io.open(filename, \"rb\") as audio_file:\n",
    "        content = audio_file.read()\n",
    "    audio = speech.RecognitionAudio(content = content)\n",
    "    config = speech.RecognitionConfig(\n",
    "        encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,\n",
    "        language_code=\"de-DE\",\n",
    "    )\n",
    "    response = client.recognize(config=config, audio=audio)\n",
    "    for result in response.results:\n",
    "        for index, alternative in enumerate(result.alternatives):\n",
    "            print(\"User: {}\".format(alternative.transcript))\n",
    "            return alternative.transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c680e705",
   "metadata": {},
   "outputs": [],
   "source": [
    "#record a query and return a transcription\n",
    "def speech_input():\n",
    "    record_file()\n",
    "    text = transcribe()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a99dea",
   "metadata": {},
   "source": [
    "### <a id=\"Semantic_parsing\">Semantic parsing</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7849318",
   "metadata": {},
   "source": [
    "`intents.json` contains a list of dictionaries which is used as a basis for training the bot to recognize a type of query. There's one dictionary for each of five possible topics (new cases, incidence, deaths, vaccinations and recovered). Each dictionary consists of three categories: <b>tag</b> - the topic of the question; <b>patterns</b> - some example questions; <b>responses</b> - a unique id number which will later be used to get specific data from the API."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76725c88",
   "metadata": {},
   "source": [
    "The bot is trained to predict a query type using `training.py` file. Detailed comments are in the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e51279cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "intents = json.loads(open(\"intents.json\").read())\n",
    "#load words, classes and model created via training.py\n",
    "words = pickle.load(open(\"words.pkl\", \"rb\"))\n",
    "classes = pickle.load(open(\"classes.pkl\", \"rb\"))\n",
    "model = load_model(\"chatbot_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a290248",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenize and lemmatize input\n",
    "def clean_up_sentence(text):\n",
    "    sentence_words = nltk.word_tokenize(text)\n",
    "    sentence_words = [hannover.analyze(word)[0] for word in sentence_words]\n",
    "    return sentence_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "092445ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert input into a bag of words\n",
    "def bag_of_words(text): \n",
    "    sentence_words = clean_up_sentence(text)\n",
    "    bag = [0] * len(words)\n",
    "    for w in sentence_words:\n",
    "        for i, word in enumerate(words):\n",
    "            if word == w:\n",
    "                bag[i] = 1\n",
    "    return np.array(bag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72bdae82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict class based on the input text\n",
    "def predict_class(text):\n",
    "    bow = bag_of_words(text) #create a bag of words\n",
    "    res = model.predict(np.array([bow]))[0] #predict the result based on the bag of words\n",
    "    ERROR_THRESHOLD = 0.85 #specify how much uncertainty we allow\n",
    "    results = [[i, r] for i, r in enumerate(res) if r > ERROR_THRESHOLD] #enumerate the results to get an index and a class\n",
    "\n",
    "    results.sort(key=lambda x: x[1], reverse=True) #sort by probability in reverse order\n",
    "    return_list = []\n",
    "    for r in results:\n",
    "        return_list.append({\"intent\": classes[r[0]], \"probability\": str(r[1])}) #return a list with categories and their probabilities\n",
    "        print(\"Prediction accuracy: \" + str(r[1]))\n",
    "    return return_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f8258d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get a unique id number of the predicted class\n",
    "def get_response(intents_list, intents_json):\n",
    "    tag = intents_list[0][\"intent\"]\n",
    "    list_of_intents = intents_json[\"intents\"]\n",
    "    for i in list_of_intents:\n",
    "        if i[\"tag\"] == tag:\n",
    "            result = i[\"responses\"][0]\n",
    "            break\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be1265c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sum up two previos functions: query to predicted class\n",
    "def query(text):\n",
    "    ints = predict_class(text)\n",
    "    res = get_response(ints, intents)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f7eca06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#search for location names in the input text using spaCy\n",
    "def ner(text):\n",
    "    doc = nlp(text)\n",
    "    if doc.ents:\n",
    "        for ent in doc.ents:\n",
    "            if ent.label_ == \"LOC\":\n",
    "                ner = str(ent.text)\n",
    "                return ner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fb73b895",
   "metadata": {},
   "outputs": [],
   "source": [
    "phrases = {'hello':'Willkommen bei der Corona Impfauskunft. Was möchtest du wissen?', \n",
    "    'goodbye':'Vielen Dank für das nette Gespräch. Bis zum nächsten Mal!'}\n",
    "\n",
    "continue_phrases = ['Hast du weitere Fragen?', 'Kann ich dir noch behilflich sein?', 'Wie kann ich dir noch helfen']\n",
    "\n",
    "farewells = {\"fertig\":\"done\", \"tschüss\":\"done\", \"danke\":\"done\", \"auf wiedersehen\":\"done\", \"nein\":\"done\"}\n",
    "\n",
    "states_shortened = {\"Baden-Württemberg\":\"BW\",\"Bayern\":\"BY\",\"Berlin\":\"BE\",\"Brandenburg\":\"BB\",\n",
    "                   \"Bremen\":\"HB\",\"Hamburg\":\"HH\",\"Hessen\":\"HE\",\"Mecklenburg-Vorpommern\":\"MV\",\n",
    "                   \"Niedersachsen\":\"NI\",\"Nordrhein-Westfalen\":\"NW\",\"Rheinland-Pfalz\":\"RP\",\n",
    "                   \"Saarland\":\"SL\",\"Sachsen\":\"SN\",\"Sachsen-Anhalt\":\"ST\",\"Schleswig-Holstein\":\"SH\",\n",
    "                   \"Thüringen\":\"TH\",\"Deutschland\":\"DE\"}\n",
    "\n",
    "states_full = {\"BW\":\"Baden-Württemberg\",\"BY\":\"Bayern\",\"BE\":\"Berlin\",\"BB\":\"Brandenburg\",\n",
    "              \"HB\":\"Bremen\",\"HH\":\"Hamburg\",\"HE\":\"Hessen\",\"MV\":\"Mecklenburg-Vorpommern\",\n",
    "              \"NI\":\"Niedersachsen\",\"NW\":\"Nordrhein-Westfalen\",\"RP\":\"Rheinland-Pfalz\",\n",
    "              \"SL\":\"Saarland\",\"SN\":\"Sachsen\",\"ST\":\"Sachsen-Anhalt\",\"SH\":\"Schleswig-Holstein\",\n",
    "              \"TH\":\"Thüringen\",\"DE\":\"Deutschland\"}\n",
    "\n",
    "vaccines_d = {'biontech':'biontech', 'bajonczak':'biontech', \n",
    "              'moderna':'moderna', 'moderner':'moderna', \"moderne\":\"moderna\",\n",
    "              'janssen':'janssen', 'johnson':'janssen',\n",
    "              'astraZeneca':'astraZeneca', 'astra':'astraZeneca', 'zeneca':'astraZeneca'}\n",
    "\n",
    "vaccine_names = {'biontech':'Biontech', 'moderna':'Moderna', 'janssen':'Janssen',\n",
    "              'astraZeneca':'AstraZeneca'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ef3a26e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check if the sentence contains any location name or vaccine name\n",
    "def semantic(input_s, ner):\n",
    "    semantics = {'state':'', \"unknown_location\":\"\", 'vaccine':'', 'answer':0}\n",
    "    for key in states_shortened.keys():\n",
    "        if ner == key:\n",
    "            semantics['state'] = states_shortened[key]\n",
    "        else:\n",
    "            semantics['unknown_location'] = ner\n",
    "    for key in vaccines_d.keys():\n",
    "        if key in input_s:\n",
    "            semantics['vaccine'] = vaccines_d[key]\n",
    "    return semantics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b1d57042",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize Eliza in German\n",
    "def init_eliza():\n",
    "    elz = eliza.Eliza()\n",
    "    elz.load(\"deutsch.txt\")\n",
    "    return elz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57cb5b1",
   "metadata": {},
   "source": [
    "### <a id=\"Data_binding\">Data binding</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85dfe00",
   "metadata": {},
   "source": [
    "`wendel_util.py` was updated so that it can create / update a json file with data for any endpoint from the Corona API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "46857f79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Up To Date\n"
     ]
    }
   ],
   "source": [
    "#create/update a file with data for Germany\n",
    "module = 'germany'\n",
    "file_update(module)\n",
    "data = open(module + '.json')\n",
    "data_germany = json.load(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "24d5b2f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Up To Date\n"
     ]
    }
   ],
   "source": [
    "#create/update a file with data regarding vaccinations\n",
    "module = 'vaccinations'\n",
    "file_update(module)\n",
    "data = open(module + '.json')\n",
    "data_vaccinations = json.load(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7d7681cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Up To Date\n"
     ]
    }
   ],
   "source": [
    "#create/update a file with data for single German states\n",
    "module = 'states'\n",
    "file_update(module)\n",
    "data = open(module + '.json')\n",
    "data_states = json.load(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5ced20be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get data from the API based on the predicted class and given information (location, vaccine)\n",
    "def data(semantics, res):\n",
    "    s = semantics['state']\n",
    "    u = semantics[\"unknown_location\"]\n",
    "    v = semantics['vaccine']\n",
    "    if s: #state given\n",
    "        if s != \"DE\": #and state does not equal \"Germany\"\n",
    "            if res == \"0\": #new cases\n",
    "                semantics['answer'] = data_states[\"data\"][s][\"delta\"][\"cases\"]\n",
    "            if res == \"1\": #incidence\n",
    "                semantics['answer'] = data_states[\"data\"][s][\"weekIncidence\"]\n",
    "            if res == \"2\": #deaths\n",
    "                semantics['answer'] = data_states[\"data\"][s][\"deaths\"]\n",
    "            if res == \"3\":  #vaccinated\n",
    "                if v: #vaccine given\n",
    "                    semantics['answer'] = data_vaccinations[\"data\"][\"states\"][s]['vaccination'][v]\n",
    "                else: #no vaccine given\n",
    "                    semantics['answer'] = data_vaccinations[\"data\"][\"states\"][s][\"vaccinated\"]\n",
    "            if res == \"4\": #recovered\n",
    "                semantics['answer'] = data_states[\"data\"][s][\"recovered\"]\n",
    "        if s == \"DE\": #and equals \"Germany\"\n",
    "            if res == \"0\": #new cases\n",
    "                semantics['answer'] = data_germany[\"delta\"][\"cases\"]\n",
    "            if res == \"1\": #incidence\n",
    "                semantics['answer'] = data_germany[\"weekIncidence\"]\n",
    "            if res == \"2\": #deaths\n",
    "                semantics['answer'] = data_germany[\"deaths\"]\n",
    "            if res == \"3\":\n",
    "                if v: #vaccine given\n",
    "                    semantics['answer'] = data_vaccinations[\"data\"]['vaccination'][v]\n",
    "                else: # no vaccine given\n",
    "                    semantics['answer'] = data_vaccinations[\"data\"][\"vaccinated\"]\n",
    "            if res == \"4\": #recovered\n",
    "                semantics['answer'] = data_germany[\"recovered\"]\n",
    "    elif u: #query about unknown location\n",
    "        semantics['answer'] = 0\n",
    "    else: #no state given\n",
    "        if res == \"0\": #new cases\n",
    "            semantics['answer'] = data_germany[\"delta\"][\"cases\"]\n",
    "        if res == \"1\": #incidence\n",
    "            semantics['answer'] = data_germany[\"weekIncidence\"]\n",
    "        if res == \"2\": #deaths\n",
    "            semantics['answer'] = data_germany[\"deaths\"]\n",
    "        if res == \"3\":\n",
    "            if v: #vaccine given\n",
    "                semantics['answer'] = data_vaccinations[\"data\"]['vaccination'][v]\n",
    "            else: # no vaccine given\n",
    "                semantics['answer'] = data_vaccinations[\"data\"][\"vaccinated\"]\n",
    "        if res == \"4\": #recovered\n",
    "            semantics['answer'] = data_germany[\"recovered\"]\n",
    "    return semantics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1588e4",
   "metadata": {},
   "source": [
    "### <a id=\"Output_and_TTS\">Output and TTS</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "23d1f6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare a final answer\n",
    "def output(semantics, res):\n",
    "    ret = ''\n",
    "    s = semantics['state']\n",
    "    u = semantics[\"unknown_location\"]\n",
    "    v = semantics['vaccine']\n",
    "    a = semantics['answer']\n",
    "    if s: #state given\n",
    "        s = states_full[s]\n",
    "        if res == \"0\": #new cases\n",
    "            ret = 'Die Anzahl von Neuinfektionen von gestern für {} ist {}'.format(s, a)\n",
    "        if res == \"1\": #incidence\n",
    "            ret = 'Die aktuelle Sieben-Tage-Inzidenz für {} beträgt {:.2f}'.format(s, a)\n",
    "        if res == \"2\": #deaths\n",
    "            ret = 'Die aktuelle Todesanzahl für {} beträgt {}'.format(s, a)\n",
    "        if res == \"3\": #vaccinated\n",
    "            if v: #vaccine given\n",
    "                v = vaccine_names[v]\n",
    "                ret = 'Die Impfungen für {} mit {} sind {}'.format(s, v, a)\n",
    "            else: #no vaccine given\n",
    "                ret = 'Die Impfungen für {} sind {}'.format(s, a)\n",
    "        if res == \"4\": #recovered\n",
    "            ret = 'Die Anzahl von Genesenen für {} beträgt {}'.format(s, a)\n",
    "    elif u: #query about unknown location\n",
    "        ret = 'Die Informationen über {} habe ich leider nicht. Besuche die Seite von der Weltgesundheitsorganisation unter www.who.int oder suche nach der Antwort in Google. Viel Erfolg!'.format(u)\n",
    "    else: # no state\n",
    "        if res == \"0\": #new cases\n",
    "            ret = 'Die Anzahl von Neuinfektionen von gestern für Deutschland ist {}'.format(a)\n",
    "        if res == \"1\": #incidence\n",
    "            ret = 'Die aktuelle Sieben-Tage-Inzidenz für Deutschland beträgt {:.2f}'.format(a)\n",
    "        if res == \"2\": #deaths\n",
    "            ret = 'Die aktuelle Todesanzahl für Deutschland beträgt {}'.format(a)\n",
    "        if res == \"3\": #vaccinated\n",
    "            if v: #vaccine given\n",
    "                v = vaccine_names[v]\n",
    "                ret = 'Die Impfungen für Deutschalnd mit {} sind {}'.format(v, a)\n",
    "            else: #no vaccine given\n",
    "                ret = 'Die Impfungen für Deutschland sind {}'.format(a)\n",
    "        if res == \"4\": #recovered\n",
    "            ret = 'Die Anzahl von Genesenen für Deutschland beträgt {}'.format(a)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c9f38899",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert text answer into speech and print it\n",
    "def tts(text):\n",
    "    engine = pyttsx3.init()\n",
    "    engine.setProperty('voice', 'german')\n",
    "    engine.setProperty('rate', 300)\n",
    "    engine.say(text)\n",
    "    engine.runAndWait()\n",
    "    print(\"Bot: \" + text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e182a3",
   "metadata": {},
   "source": [
    "### <a id=\"Dialog_manager\">Dialog manager</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6d3cb636",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function manages the whole chatbot\n",
    "#if the bot recognizes one of five query types with prediction accuracy over 85%, it give an answer\n",
    "#otherwise Eliza is switched on\n",
    "def dialogmanager():\n",
    "    tts(phrases['hello'])\n",
    "    input_s = speech_input()\n",
    "    while input_s and input_s.lower() not in farewells.keys():\n",
    "        try:\n",
    "            res = query(input_s) # predict the type of query\n",
    "            location = ner(input_s) # searching for location names in the input string\n",
    "            semantics = semantic(input_s, location)\n",
    "            semantics = data(semantics, res)\n",
    "            out_string = output(semantics, res)\n",
    "            tts(out_string)\n",
    "            tts(random.choice(continue_phrases))\n",
    "            input_s = speech_input()\n",
    "        except:\n",
    "            tts(elz.respond(input_s))\n",
    "            tts(random.choice(continue_phrases))\n",
    "            input_s = speech_input()\n",
    "    tts(phrases['goodbye'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0251cbe8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: Willkommen bei der Corona Impfauskunft. Was möchtest du wissen?\n",
      "User: aktuelle Inzidenz für Hamburg\n",
      "Prediction accuracy: 0.999938\n",
      "Bot: Die aktuelle Sieben-Tage-Inzidenz für Hamburg beträgt 82.32\n",
      "Bot: Kann ich dir noch behilflich sein?\n",
      "User: wie viele Menschen haben Corona überstanden\n",
      "Prediction accuracy: 0.8507149\n",
      "Bot: Die Anzahl von Genesenen für Deutschland beträgt 3731886\n",
      "Bot: Kann ich dir noch behilflich sein?\n",
      "User: wie viele Menschen sind in Bremen gestorben\n",
      "Prediction accuracy: 0.9998779\n",
      "Bot: Die aktuelle Todesanzahl für Bremen beträgt 498\n",
      "Bot: Hast du weitere Fragen?\n",
      "User: Menschen sind in Berlin mit biontech geimpft\n",
      "Prediction accuracy: 0.99999976\n",
      "Bot: Die Impfungen für Berlin mit Biontech sind 1663647\n",
      "Bot: Wie kann ich dir noch helfen\n",
      "User: neue Fälle wurden in Niedersachsen gemeldet\n",
      "Prediction accuracy: 0.99999905\n",
      "Bot: Die Anzahl von Neuinfektionen von gestern für Niedersachsen ist 308\n",
      "Bot: Kann ich dir noch behilflich sein?\n",
      "User: ist die aktuelle Inzidenz für London\n",
      "Prediction accuracy: 0.9999943\n",
      "Bot: Die Informationen über London habe ich leider nicht. Besuche die Seite von der Weltgesundheitsorganisation unter www.who.int oder suche nach der Antwort in Google. Viel Erfolg!\n",
      "Bot: Wie kann ich dir noch helfen\n",
      "User: die Eintrittskarte ins Bode-Museum\n",
      "Bot: Ich bin nicht sicher, ob ich dich verstanden habe.\n",
      "Bot: Wie kann ich dir noch helfen\n",
      "User: tschüss\n",
      "Bot: Vielen Dank für das nette Gespräch. Bis zum nächsten Mal!\n"
     ]
    }
   ],
   "source": [
    "#initialize dialogmanager and eliza\n",
    "elz = init_eliza()\n",
    "dialogmanager()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
